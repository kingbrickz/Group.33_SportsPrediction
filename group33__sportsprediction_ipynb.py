# -*- coding: utf-8 -*-
"""Group33._SportsPrediction.ipynb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cimy7DYzuP5toYkge4hiXTAevB1llGz5
"""

import pandas as pd
import os
import sklearn
import numpy as np
import pandas as pd
import numpy as np, pandas as pd
import matplotlib.pyplot as plt
from sklearn import tree, metrics
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from google.colab import drive
drive.mount('/content/drive')

"""cleaning of data"""

fifa_21=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/ai/players_21.csv")

missing_values = fifa_21.isna().sum() / fifa_21.shape[0] * 100
columns_to_drop = missing_values[missing_values > 30].index.tolist()
fifa_21 = fifa_21.drop(columns_to_drop, axis=1)
fifa_21.to_csv('dataset_with_missing_values_removed.csv', index=False)
fifa_21

correlation_matrix = fifa_21.corr()



"""feature selection"""

selected_features= correlation_matrix['overall'].sort_values(ascending=False).index
selected_features[:10]

selected_features=[ 'overall', 'movement_reactions', 'passing', 'mentality_composure',
       'dribbling', 'potential', 'release_clause_eur', 'wage_eur', 'value_eur',
       'power_shot_power']

new_df = selected_features.copy()
new_fifa=pd.DataFrame(fifa_21[new_df])
new_fifa

new_fifa = new_fifa.fillna(new_fifa.mean())
new_fifa

new_fifa

row_index = 0
new_fifa.loc[row_index, 'overall'] = 92
new_fifa.to_csv('updated_dataset.csv', index=False)
new_fifa

data=new_fifa.copy()

data



"""training and testing"""

y=new_fifa['overall']

X=new_fifa[[ 'movement_reactions', 'passing', 'mentality_composure',
       'dribbling', 'potential', 'release_clause_eur', 'wage_eur', 'value_eur',
       'power_shot_power']]

sc=StandardScaler()
scaled=sc.fit_transform(X)
X=pd.DataFrame(scaled, columns=X.columns)

Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()
rf.fit(Xtrain, Ytrain)

from sklearn.metrics import accuracy_score

y_pred=rf.predict(Xtest)
y_pred

from sklearn.metrics import mean_absolute_error, mean_squared_error

mean_absolute_error(y_pred,Ytest)

from sklearn.tree import DecisionTreeRegressor

dt = DecisionTreeRegressor()
dt.fit(Xtrain, Ytrain)

y_pred = dt.predict(Xtest)
y_pred

mae=mean_squared_error(y_pred,Ytest)
mae

from xgboost import XGBRegressor

xgb = XGBRegressor()

xgb.fit(Xtrain, Ytrain)

y_pred = xgb.predict(Xtest)

y_pred

mse = mean_absolute_error(Ytest, y_pred)
mse

"""optimization and fine tuning"""

from sklearn.model_selection import RandomizedSearchCV
param_distributions = {
    'n_estimators': np.arange(10, 50, step=10),
    'max_depth': np.arange(2, 12, step=1)
}
n_iter = 100
random_search = RandomizedSearchCV(
    estimator=RandomForestRegressor(),
    param_distributions=param_distributions,
    n_iter=n_iter,
    cv=5
)
random_search.fit(Xtrain, Ytrain)

best_params = random_search.best_params_
best_rf = RandomForestRegressor(**best_params)
best_rf.fit(Xtrain, Ytrain)

y_pred = best_rf.predict(Xtest)
mse = mean_squared_error(Ytest, y_pred)
mse

param_distributions = {
    'max_depth': np.arange(2, 10, step=1),
    'min_samples_split': np.arange(2, 100, step=10),
    'max_features': np.arange(1, 10, step=1)
}
n_iter = 100
random_search = RandomizedSearchCV(
    estimator=DecisionTreeRegressor(),
    param_distributions=param_distributions,
    n_iter=n_iter,
    cv=5
)
random_search.fit(Xtrain, Ytrain)

best_params = random_search.best_params_
best_dt = DecisionTreeRegressor(**best_params)
best_dt.fit(Xtrain, Ytrain)

y_pred = best_dt.predict(Xtest)
mean_squared_error(Ytest, y_pred)

param_distributions = {
    'n_estimators': np.arange(100, 500, step=100),
    'max_depth': np.arange(2, 10, step=1),
    'learning_rate': np.arange(0.01, 0.1, step=0.01),
    'gamma': np.arange(0, 1, step=0.1),
    'subsample': np.arange(0.5, 1, step=0.1),
    'colsample_bytree': np.arange(0.5, 1, step=0.1)
}
n_iter = 100
random_search = RandomizedSearchCV(
    estimator=XGBRegressor(),
    param_distributions=param_distributions,
    n_iter=n_iter,
    cv=5
)
random_search.fit(Xtrain, Ytrain)

best_params = random_search.best_params_
best_xgb = XGBRegressor(**best_params)
best_xgb.fit(Xtrain, Ytrain)

y_pred = best_xgb.predict(Xtest)
mean_squared_error(Ytest, y_pred)

#COMPARING WITH FIFA 2022
fifa_22=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/ai/players_22.csv")
fifa_22

correlation_matrix = fifa_22.corr()

features_22= correlation_matrix['overall'].sort_values(ascending=False).index
features_22[:10]

features_22=['overall', 'movement_reactions', 'passing', 'mentality_composure',
       'dribbling', 'potential', 'release_clause_eur', 'wage_eur', 'value_eur',
       'power_shot_power']

df_22 = features_22.copy()
newff_22=pd.DataFrame(fifa_22[df_22])
newff_22

newff_22 = newff_22.fillna(newff_22.mean())
newff_22

row_index = 0
newff_22.loc[row_index, 'overall'] = 92
newff_22.to_csv('updated_dataset.csv', index=False)
newff_22

data_22=newff_22.copy()
data_22

y=newff_22['overall']
X=newff_22[[ 'movement_reactions', 'passing', 'mentality_composure',
       'dribbling', 'potential', 'release_clause_eur', 'wage_eur', 'value_eur',
       'power_shot_power']]

sc=StandardScaler()
scaled=sc.fit_transform(X)
X=pd.DataFrame(scaled, columns=X.columns)

Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

from sklearn.ensemble import RandomForestRegressor
rf_22 = RandomForestRegressor()
rf_22.fit(Xtrain, Ytrain)

y_22=rf_22.predict(Xtest)
y_22

mean_absolute_error(y_22,Ytest)

dt_22 = DecisionTreeRegressor(random_state=42)
dt_22.fit(Xtrain, Ytrain)

y_22 = dt_22.predict(Xtest)
y_22

mean_absolute_error(y_22,Ytest)

xgb_22 = XGBRegressor()
xgb_22.fit(Xtrain, Ytrain)

xgb_22

xgb_22_prediction = xgb_22.predict(Xtest)

mean_absolute_error(xgb_22,Ytest)

#finetune decisiontree for fifa22
param_distributions = {
    'max_depth': np.arange(2, 10, step=1),
    'min_samples_split': np.arange(2, 30, step=10),
    'max_features': np.arange(1, 12, step=1)
}
n_iter = 30
random_search_22 = RandomizedSearchCV(
    estimator=DecisionTreeRegressor(),
    param_distributions=param_distributions,
    n_iter=n_iter,
    cv=5
)
random_search_22.fit(Xtrain, Ytrain)

best_params = random_search_22.best_params_
best22_dt = DecisionTreeRegressor(**best_params)
best22_dt.fit(Xtrain, Ytrain)

y_pred_22 = best_dt.predict(Xtest)
mean_absolute_error(Ytest, y_pred_22)

"""saving model as pickle file"""

import pickle
import joblib

joblib.dump(xgb_22, 'xgb_22.pkl')

model_saved='/content/drive/MyDrive/Colab Notebooks/xgb_22.pkl'
with open(model_saved,'wb')as file:
  pickle.dump(xgb_22,file)

xgb_22

